{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M6LNC09V-anD"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "Xr88UDHZ-1ML"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYyXYyiA-63v",
        "outputId": "f63ce534-b0a2-4675-a7ff-6f54564d4eee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "zYAosQ5B-8NQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyspark==3.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHRSKNiD--s-",
        "outputId": "c825d16e-776b-4ce4-fcf5-e7d867f44a03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.0.0\n",
            "  Downloading pyspark-3.0.0.tar.gz (204.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.7/204.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9 (from pyspark==3.0.0)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044159 sha256=8cd03a149bcd91cb3c8b4f33cebfde0d7332d302d6457c28b6412bb9933c3297\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/bb/8b/ca24d3f756f2ed967225b0871898869db676eb5846df5adc56\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализируем\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import DoubleType, IntegerType, ArrayType, StringType\n",
        "from pyspark.sql.functions import udf, explode, rank, col, max, sum, desc, countDistinct\n",
        "import re\n",
        "from typing import List\n",
        "import pyspark.sql as sql"
      ],
      "metadata": {
        "id": "M1eEXGll_E32"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"L2_reports_with_apache_spark\") \\\n",
        "    .config(\"spark.jars.packages\", \"com.databricks:spark-xml_2.12:0.13.0\") \\\n",
        "    .getOrCreate()\n",
        "spark.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CBvCfBmk_LoM",
        "outputId": "f33b401e-caad-4365-a0cd-fdf5d5bdf298"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.1.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем данные\n",
        "import os\n",
        "program_path = '/content/programming-languages.csv' # список языков\n",
        "posts_path = '/content/posts_sample.xml' # выборка данных"
      ],
      "metadata": {
        "id": "Sr1DYSUQ_ZXU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаем данные из файла в формате xml и каждую строку обернем в тег row\n",
        "posts = spark.read.format('xml').options(rowTag='row').load(posts_path)"
      ],
      "metadata": {
        "id": "N1v49iyn_z9q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаем данные из файла csv\n",
        "program = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .option(\"inferSchema\", True) \\\n",
        "      .option(\"DateTimeFormat\", 'M/d/y H:m') \\\n",
        "      .csv(program_path)"
      ],
      "metadata": {
        "id": "b2SrAXjWBCym"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: Сформировать отчёт с информацией о 10 наиболее популярных языках программирования по итогам года за период с 2010 по 2020 годы.\n",
        "Получившийся отчёт сохранить в формате Apache Parquet."
      ],
      "metadata": {
        "id": "rUjriGcY-p5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tags(string_tag):\n",
        "    if string_tag is None:\n",
        "        return []\n",
        "    reg = r'<(.+?)>' # создаем шаблон регулярного выражения\n",
        "    tags_list = re.findall(reg, string_tag) # извлекаем все совпадения и возвращаем список тегов\n",
        "    return tags_list\n",
        "\n",
        "def get_year(date_and_time):\n",
        "    return date_and_time.year # возвращаем год из даты\n",
        "\n",
        "# Используем пользовательские функции с udf\n",
        "get_tags_list_udf = udf(get_tags, ArrayType(StringType())) # принимаем строку и возвращаем список строк\n",
        "get_year_udf = udf(get_year, IntegerType()) # возвращаем целое число\n",
        "\n",
        "# Добавляем два новых столбца к dataFrame\n",
        "posts_data_simplified = posts \\\n",
        "                    .withColumn(\"tags\", get_tags_list_udf(posts[\"_Tags\"])) \\\n",
        "                    .withColumn(\"year\", get_year_udf(posts[\"_LastActivityDate\"]))\n",
        "\n",
        "posts_data_simplified = posts_data_simplified.select(col(\"tags\"), col(\"year\"), col(\"_ViewCount\").alias(\"views\"))\n",
        "first_rows = posts_data_simplified.head(10) # сохраняем первые 10 строк из dataFrame\n",
        "for i, row in enumerate(first_rows):\n",
        "    print(i+1, row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ZUa6x4BlWb",
        "outputId": "ce67c9e1-485e-483a-e364-09f43fed3abd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Row(tags=['c#', 'floating-point', 'type-conversion', 'double', 'decimal'], year=2019, views=42817)\n",
            "2 Row(tags=['html', 'css', 'internet-explorer-7'], year=2019, views=18214)\n",
            "3 Row(tags=[], year=2017, views=None)\n",
            "4 Row(tags=['c#', '.net', 'datetime'], year=2019, views=555183)\n",
            "5 Row(tags=['c#', 'datetime', 'time', 'datediff', 'relative-time-span'], year=2019, views=149445)\n",
            "6 Row(tags=[], year=2018, views=None)\n",
            "7 Row(tags=['html', 'browser', 'timezone', 'user-agent', 'timezone-offset'], year=2019, views=176405)\n",
            "8 Row(tags=['.net', 'math'], year=2018, views=123231)\n",
            "9 Row(tags=[], year=2010, views=None)\n",
            "10 Row(tags=[], year=2010, views=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Теперь отсортируем, чтобы узнать самые популярные языки\n",
        "\n",
        "# разобъем tags на отдельные строки\n",
        "posts_sorted = posts_data_simplified.select(\"year\", explode(\"tags\").alias(\"tag\"), \"views\")\n",
        "\n",
        "# Группируем по году последней активности и тегам\n",
        "# для каждого года и тега вычисляем сумму просмотров (в пределах одного года)\n",
        "posts_sorted = posts_sorted.groupBy(\"year\", \"tag\").agg(sum(\"views\").alias(\"total_views\"))\n",
        "\n",
        "# Сортируем по убыванию количества просмотров\n",
        "posts_sorted = posts_sorted.orderBy(\"year\", desc(\"total_views\"))\n",
        "posts_sorted.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkbvVeFrDJQW",
        "outputId": "9ad49217-8dfd-4378-ce22-9310adc72db5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+-----------+\n",
            "|year|          tag|total_views|\n",
            "+----+-------------+-----------+\n",
            "|2008|           c#|      25401|\n",
            "|2008|         .net|      24321|\n",
            "|2008|     database|      19682|\n",
            "|2008|        local|      19682|\n",
            "|2008|         java|      11532|\n",
            "|2008|  inheritance|      10971|\n",
            "|2008|accessibility|       7700|\n",
            "|2008|    variables|       7700|\n",
            "|2008|        excel|       6540|\n",
            "|2008|   automation|       6540|\n",
            "+----+-------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Отсортируем по популярности\n",
        "\n",
        "# Определяем спецификацию Window (отсортирована по годам и в порядке убывания по total_views)\n",
        "window = Window.partitionBy(\"year\").orderBy(posts_sorted[\"total_views\"].desc())\n",
        "\n",
        "# Добавляем колонку rank в dataFrame\n",
        "# (содержит ранг каждой строки внутри окна)\n",
        "rank_df = posts_sorted.withColumn(\"rank\", rank().over(window))\n",
        "\n",
        "# Фильтруем ранг\n",
        "result_df = rank_df.filter(rank_df[\"rank\"] <= 5)\n",
        "\n",
        "# Сортируем по году и делаем в порядке убывания по количеству просмотров\n",
        "result_df = result_df.select(\"year\", \"tag\", \"total_views\")\n",
        "data_sorted_result = result_df.orderBy(\"year\", desc(\"total_views\"))\n",
        "\n",
        "data_sorted_result.show()\n",
        "\n",
        "# Записываем в формате Apache Parquet\n",
        "data_sorted_result.write.parquet(\"data_posts_sorted_result.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F_bqlAjG3dx",
        "outputId": "33f6a847-947a-45dc-8a72-cc0416346d16"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+-----------+\n",
            "|year|                 tag|total_views|\n",
            "+----+--------------------+-----------+\n",
            "|2008|                  c#|      25401|\n",
            "|2008|                .net|      24321|\n",
            "|2008|            database|      19682|\n",
            "|2008|               local|      19682|\n",
            "|2008|                java|      11532|\n",
            "|2009|                  c#|      73661|\n",
            "|2009|                .net|      39167|\n",
            "|2009|              python|      32219|\n",
            "|2009|                 c++|      29381|\n",
            "|2009|            winforms|      25670|\n",
            "|2010|                  c#|     128597|\n",
            "|2010|              arrays|      80868|\n",
            "|2010|                java|      53333|\n",
            "|2010|multidimensional-...|      51865|\n",
            "|2010|              matlab|      51865|\n",
            "|2011|                  c#|     238076|\n",
            "|2011|                java|     121315|\n",
            "|2011|                .net|     120734|\n",
            "|2011|                 css|     119302|\n",
            "|2011|             android|     107283|\n",
            "+----+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Тут я столкнулась с проблемой когда перезапускала код\n",
        "# AnalysisException: path file:/content/data_posts_sorted_result.parquet already exists.\n",
        "# Оказывается можно удалять только пустые каталоги\n",
        "import shutil"
      ],
      "metadata": {
        "id": "btGnSY7ZJw41"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удалим каталог\n",
        "path_dir = \"data_posts_sorted_result.parquet\"\n",
        "shutil.rmtree(path_dir)"
      ],
      "metadata": {
        "id": "dYKj1cW7JU1w"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}